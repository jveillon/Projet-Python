{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d52f9621-910c-4c05-bb30-465202e68858",
   "metadata": {},
   "source": [
    "Après avoir sélectionné la méthode de clustering la plus efficace, nous allons analyser le vocabulaire utilisé dans les tweets de chaque cluster.\n",
    "Avant toute chose, il est nécessaire de nettoyer les tweets, c'est-à-dire de supprimer la ponctuation, les majuscules, les caractères spéciaux, les emojis, etc.\n",
    "On va également créer une liste de stopwords à supprimer.\n",
    "La fonction suivante prend en argument un texte et renvoie le texte nettoyé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "783ad3ea-9e26-44ac-85d3-54d4123044bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting demoji\n",
      "  Downloading demoji-1.1.0-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: demoji\n",
      "Successfully installed demoji-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a91bf9a-91ab-4719-82fb-d92881192051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import demoji\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import wordcloud\n",
    "import numpy as np\n",
    "import io\n",
    "import requests\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea42d9b-1d3b-4238-80b0-3da7836c310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rajouter les mots qui apparaissent très souvent et qui ne sont pas utiles pour l'analyse\n",
    "stop_words_context = [\"france\", \"pologne\", \"but\"]\n",
    "stop_words = set(stopwords.words('french'))\n",
    "stop_words = list(stop_words) + stop_words_context\n",
    "\n",
    "def rm_stopwords(text):\n",
    "    return [w for w in text.split() if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8134250e-053c-468d-9597-c5b43fc7d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    #tout mettre en minuscules\n",
    "    text = text.lower()\n",
    "    #suppression de la ponctuation\n",
    "    punct = string.punctuation\n",
    "    text = text.translate(str.maketrans(\", \", punct))\n",
    "    #suppression des chiffres (pour une analyse de vocabulaire, ils ne sont pas nécessaires)\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    #suppression des emojis\n",
    "    for item in demoji.findall(text):\n",
    "        text =text.replace(item,\"\")\n",
    "    #suppression des mentions\n",
    "    text = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "    #suppression des hashtags\n",
    "    text = re.sub(\"#[A-Za-z0-9_]+\",\"\", text)\n",
    "    #suppression des stopwords\n",
    "    text = rm_stopwords(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a307891-dd10-47f2-9391-ecce08ee3d97",
   "metadata": {},
   "source": [
    "On va ensuite créer un wordcloud pour chaque cluster.\n",
    "Première étape : dans le dataframe des tweets, créer une nouvelle variable \"clean text\" qui contient le texte des tweets modifiés grâce à la fonction clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71030dc-da69-42fa-b727-4c4d33a90103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_text\"] = df[\"text\"].apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa35d79-ea6d-45e3-9d80-0d629e955a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "def make_wordcloud(corpus):\n",
    "    wc = wordcloud.WordCloud(background_color=\"white\", max_words=2000)\n",
    "    wc.generate(corpus)\n",
    "    return wc\n",
    "\n",
    "#j'ai repris le code du TP, il faudra faire une boucle pour appliquer ça à chaque cluster\n",
    "plt.imshow(make_wordcloud(dumas), interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce5f3ef-c507-47f7-8ab5-9f8b35d3052d",
   "metadata": {},
   "source": [
    "On va maintenant créer différentes variables concernant les tweets, de manière à analyser d'autres caractéristiques que le vocabulaire.\n",
    "Pour notre analyse, il peut être utile de connaître le nombre de hashtags dans chaque tweet, le nombre de majuscules ainsi que le nombre de points d'exclamation.\n",
    "Le dataframe initial contient déjà le nombre de likes et de retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b24580-ffe4-4b2a-9c4e-6fa3f6447f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hashtags(text):\n",
    "    find = re.compile(\"([#]\\w+)\").findall(text)\n",
    "    return len(find)\n",
    "\n",
    "df[\"nb_hashtags\"] = df[\"text\"].apply(lambda x : count_hashtags(x))\n",
    "\n",
    "def count_exclamation(text):\n",
    "    find = re.compile(\"(\\w?\\s?[!])\").findall(text)\n",
    "    return len(find)\n",
    "\n",
    "df[\"nb_exclamation\"] = df[\"text\"].apply(lambda x : count_exclamation(x))\n",
    "\n",
    "def count_maj(text):\n",
    "    find = re.compile(\"([A-Z][A-Z]+)\").findall(text)\n",
    "    return len(find)\n",
    "\n",
    "df[\"nb_maj\"] = df[\"text\"].apply(lambda x : count_maj(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
