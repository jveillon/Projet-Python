{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47362fc4-5645-470b-9fa2-15797776597f",
   "metadata": {},
   "source": [
    "# Analyse des clusters obtenus par la m√©thode de Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "783ad3ea-9e26-44ac-85d3-54d4123044bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting demoji\n",
      "  Downloading demoji-1.1.0-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: demoji\n",
      "Successfully installed demoji-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fea95dd-a883-4415-9b44-d1def3a0b09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.8.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (458 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m458.9/458.9 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow in /opt/mamba/lib/python3.10/site-packages (from wordcloud) (9.2.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/mamba/lib/python3.10/site-packages (from wordcloud) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in /opt/mamba/lib/python3.10/site-packages (from wordcloud) (3.6.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->wordcloud) (4.38.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/mamba/lib/python3.10/site-packages (from matplotlib->wordcloud) (1.0.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/mamba/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.8.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a91bf9a-91ab-4719-82fb-d92881192051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import string\n",
    "import demoji\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import wordcloud\n",
    "import numpy as np\n",
    "import io\n",
    "import requests\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f347b1f-2603-4be3-a543-df0a26fdeabc",
   "metadata": {},
   "source": [
    "Premi√®re √©tape : on cr√©e un dataframe contenant les tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcb7be54-af26-432a-8850-c6fe7fe77ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>523849904</td>\n",
       "      <td>2022-12-13 21:14:43+00:00</td>\n",
       "      <td>[1602774039013240833]</td>\n",
       "      <td>1602774039013240832</td>\n",
       "      <td>Mon mari est en d√©pression parce qu‚Äôon ne verr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1546342369385226240</td>\n",
       "      <td>2022-12-13 21:14:33+00:00</td>\n",
       "      <td>[1602773998110216192]</td>\n",
       "      <td>1602773998110216192</td>\n",
       "      <td>BIEN MESSI. #ARGCRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1600649374022995968</td>\n",
       "      <td>2022-12-13 21:14:32+00:00</td>\n",
       "      <td>[1602773991353090050]</td>\n",
       "      <td>1602773991353090048</td>\n",
       "      <td>Les @ qui disent que Messi √©tait invisible con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>491271694</td>\n",
       "      <td>2022-12-13 21:14:27+00:00</td>\n",
       "      <td>[1602773973141446656]</td>\n",
       "      <td>1602773973141446656</td>\n",
       "      <td>Messi c‚Äôest vraiment un joueur #ARGCRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1088810623465590784</td>\n",
       "      <td>2022-12-13 21:14:27+00:00</td>\n",
       "      <td>[1602773970817785856]</td>\n",
       "      <td>1602773970817785856</td>\n",
       "      <td>Messi magic ü™Ñ #ARGCRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1379055842</td>\n",
       "      <td>2022-12-13 21:14:24+00:00</td>\n",
       "      <td>[1602773960424407041]</td>\n",
       "      <td>1602773960424407040</td>\n",
       "      <td>Motm ? #ARGCRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>962673658119557120</td>\n",
       "      <td>2022-12-13 21:14:20+00:00</td>\n",
       "      <td>[1602773943848505345]</td>\n",
       "      <td>1602773943848505344</td>\n",
       "      <td>Bof trop c'est trop, Kiki, tu es en mission ‚öîÔ∏è...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1570515228768587776</td>\n",
       "      <td>2022-12-13 21:14:19+00:00</td>\n",
       "      <td>[1602773937985040384]</td>\n",
       "      <td>1602773937985040384</td>\n",
       "      <td>Boateng peut enfin √™tre soulag√©, un h√©ritier a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>629486394</td>\n",
       "      <td>2022-12-13 21:14:15+00:00</td>\n",
       "      <td>[1602773922746978306]</td>\n",
       "      <td>1602773922746978304</td>\n",
       "      <td>#FIFAWorldCup L'Argentine, premier pays qualif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1536397663</td>\n",
       "      <td>2022-12-13 21:14:14+00:00</td>\n",
       "      <td>[1602773915113328644]</td>\n",
       "      <td>1602773915113328640</td>\n",
       "      <td>Avec un Messi des grands jours victoire amplem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id                created_at edit_history_tweet_ids  \\\n",
       "0            523849904 2022-12-13 21:14:43+00:00  [1602774039013240833]   \n",
       "1  1546342369385226240 2022-12-13 21:14:33+00:00  [1602773998110216192]   \n",
       "2  1600649374022995968 2022-12-13 21:14:32+00:00  [1602773991353090050]   \n",
       "3            491271694 2022-12-13 21:14:27+00:00  [1602773973141446656]   \n",
       "4  1088810623465590784 2022-12-13 21:14:27+00:00  [1602773970817785856]   \n",
       "5           1379055842 2022-12-13 21:14:24+00:00  [1602773960424407041]   \n",
       "6   962673658119557120 2022-12-13 21:14:20+00:00  [1602773943848505345]   \n",
       "7  1570515228768587776 2022-12-13 21:14:19+00:00  [1602773937985040384]   \n",
       "8            629486394 2022-12-13 21:14:15+00:00  [1602773922746978306]   \n",
       "9           1536397663 2022-12-13 21:14:14+00:00  [1602773915113328644]   \n",
       "\n",
       "                    id                                               text  \n",
       "0  1602774039013240832  Mon mari est en d√©pression parce qu‚Äôon ne verr...  \n",
       "1  1602773998110216192                                BIEN MESSI. #ARGCRO  \n",
       "2  1602773991353090048  Les @ qui disent que Messi √©tait invisible con...  \n",
       "3  1602773973141446656             Messi c‚Äôest vraiment un joueur #ARGCRO  \n",
       "4  1602773970817785856                              Messi magic ü™Ñ #ARGCRO  \n",
       "5  1602773960424407040                                     Motm ? #ARGCRO  \n",
       "6  1602773943848505344  Bof trop c'est trop, Kiki, tu es en mission ‚öîÔ∏è...  \n",
       "7  1602773937985040384  Boateng peut enfin √™tre soulag√©, un h√©ritier a...  \n",
       "8  1602773922746978304  #FIFAWorldCup L'Argentine, premier pays qualif...  \n",
       "9  1602773915113328640  Avec un Messi des grands jours victoire amplem...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"tweets.json\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0107b8-9a34-4176-83fe-43b4a4bc4a43",
   "metadata": {},
   "source": [
    "Deuxi√®me √©tape : cr√©er une variable qui contient le num√©ro de cluster de chaque utilisateur.\n",
    "On cr√©e d'abord un dictionnaire dont les cl√©s sont les ids des utilisateurs et les valeurs sont les num√©ros de cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99e2aa19-ace6-46c8-a857-c58cb67f1c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On r√©cup√®re les labels\n",
    "values = np.loadtxt(\"labels_louvain.txt\")\n",
    "\n",
    "#On r√©cup√®re le dictionnaire des utilisateurs\n",
    "with open('dictionnaire_following-v2.json', 'r') as fp:\n",
    "    dictionnaire = json.load(fp)\n",
    "keys = dictionnaire.keys()\n",
    "\n",
    "# pour l'instant, un dictionnaire o√π chaque cl√© renvoie √† None\n",
    "clusters = dictionnaire.fromkeys(keys)\n",
    "\n",
    "for i,key in enumerate(list(keys)) :\n",
    "    clusters[key] = int(values[i])\n",
    "    \n",
    "num_cluster = []\n",
    "for id in df['author_id']:\n",
    "    num_cluster.append(clusters.get(id))\n",
    "\n",
    "df['id_cluster'] = num_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65527875-681b-47fa-85b5-86e59483c496",
   "metadata": {},
   "source": [
    "Nous allons analyser le vocabulaire utilis√© dans les tweets de chaque cluster.\n",
    "Avant toute chose, il est n√©cessaire de nettoyer les tweets, c'est-√†-dire de supprimer la ponctuation, les majuscules, les caract√®res sp√©ciaux, les emojis, etc.\n",
    "On va √©galement cr√©er une liste de stopwords √† supprimer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ea42d9b-1d3b-4238-80b0-3da7836c310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rajouter les mots qui apparaissent tr√®s souvent et qui ne sont pas utiles pour l'analyse\n",
    "stop_words_context = [\"argentine\", \"croatie\", \"but\", \"argcro\"]\n",
    "stop_words = set(stopwords.words('french'))\n",
    "stop_words = list(stop_words) + stop_words_context\n",
    "\n",
    "def rm_stopwords(text):\n",
    "    return [w for w in text.split() if w not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb17efb-dc4b-4cd4-afc7-02f912fa9905",
   "metadata": {},
   "source": [
    "\n",
    "La fonction suivante prend en argument un texte et renvoie le texte nettoy√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8134250e-053c-468d-9597-c5b43fc7d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    #tout mettre en minuscules\n",
    "    text = text.lower()\n",
    "    #suppression de la ponctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    #suppression des chiffres (pour une analyse de vocabulaire, ils ne sont pas n√©cessaires)\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    #suppression des emojis\n",
    "    for item in demoji.findall(text):\n",
    "        text =text.replace(item,\"\")\n",
    "    #suppression des mentions\n",
    "    text = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "    #suppression des hashtags\n",
    "    text = re.sub(\"#[A-Za-z0-9_]+\",\"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a307891-dd10-47f2-9391-ecce08ee3d97",
   "metadata": {},
   "source": [
    "On va ensuite cr√©er un wordcloud pour chaque cluster.\n",
    "Premi√®re √©tape : dans le dataframe des tweets, cr√©er une nouvelle variable \"clean text\" qui contient le texte des tweets modifi√©s gr√¢ce √† la fonction clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d71030dc-da69-42fa-b727-4c4d33a90103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_text\"] = df[\"text\"].apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d0cf1710-3500-4869-b4e6-afb42941fdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "type(df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ffa35d79-ea6d-45e3-9d80-0d629e955a1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [54], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wc\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#j'ai repris le code du TP, il faudra faire une boucle pour appliquer √ßa √† chaque cluster\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mmake_wordcloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclean_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [54], line 5\u001b[0m, in \u001b[0;36mmake_wordcloud\u001b[0;34m(corpus)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_wordcloud\u001b[39m(corpus):\n\u001b[1;32m      4\u001b[0m     wc \u001b[38;5;241m=\u001b[39m wordcloud\u001b[38;5;241m.\u001b[39mWordCloud(stopwords \u001b[38;5;241m=\u001b[39m stop_words, background_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mwc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wc\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/wordcloud/wordcloud.py:639\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/wordcloud/wordcloud.py:620\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_from_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m     words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_from_frequencies(words)\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/wordcloud/wordcloud.py:582\u001b[0m, in \u001b[0;36mWordCloud.process_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    579\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_word_length \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]+\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m regexp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregexp \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregexp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pattern\n\u001b[0;32m--> 582\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;66;03m# remove 's\u001b[39;00m\n\u001b[1;32m    584\u001b[0m words \u001b[38;5;241m=\u001b[39m [word[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m word\n\u001b[1;32m    585\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/re.py:240\u001b[0m, in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfindall\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a list of all non-overlapping matches in the string.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m    If one or more capturing groups are present in the pattern, return\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    238\u001b[0m \n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "def make_wordcloud(corpus):\n",
    "    wc = wordcloud.WordCloud(stopwords = stop_words, background_color=\"white\", max_words=2000)\n",
    "    wc.generate(corpus)\n",
    "    return wc\n",
    "\n",
    "#j'ai repris le code du TP, il faudra faire une boucle pour appliquer √ßa √† chaque cluster\n",
    "plt.imshow(make_wordcloud(df[\"clean_text\"]), interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce5f3ef-c507-47f7-8ab5-9f8b35d3052d",
   "metadata": {},
   "source": [
    "On va maintenant cr√©er diff√©rentes variables concernant les tweets, de mani√®re √† analyser d'autres caract√©ristiques que le vocabulaire.\n",
    "Pour notre analyse, il peut √™tre utile de conna√Ætre le nombre de hashtags dans chaque tweet, le nombre de majuscules ainsi que le nombre de points d'exclamation.\n",
    "Le dataframe initial contient d√©j√† le nombre de likes et de retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28b24580-ffe4-4b2a-9c4e-6fa3f6447f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hashtags(text):\n",
    "    find = re.compile(\"([#]\\w+)\").findall(text)\n",
    "    return len(find)\n",
    "\n",
    "df[\"nb_hashtags\"] = df[\"text\"].apply(lambda x : count_hashtags(x))\n",
    "\n",
    "def count_exclamation(text):\n",
    "    find = re.compile(\"(\\w?\\s?[!])\").findall(text)\n",
    "    return len(find)\n",
    "\n",
    "df[\"nb_exclamation\"] = df[\"text\"].apply(lambda x : count_exclamation(x))\n",
    "\n",
    "def count_maj(text):\n",
    "    find = re.compile(\"([A-Z][A-Z]+)\").findall(text)\n",
    "    return len(find)\n",
    "\n",
    "df[\"nb_maj\"] = df[\"text\"].apply(lambda x : count_maj(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b868e438-b658-4a0a-8dcd-171ef31c2e33",
   "metadata": {},
   "source": [
    "Statistiques descriptives sur les variables, par cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23aa3118-3758-4af5-bdd5-7df0afb78c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>id</th>\n",
       "      <th>nb_hashtags</th>\n",
       "      <th>nb_exclamation</th>\n",
       "      <th>nb_maj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.054000e+03</td>\n",
       "      <td>9.054000e+03</td>\n",
       "      <td>9054.000</td>\n",
       "      <td>9054.000</td>\n",
       "      <td>9054.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.905736e+17</td>\n",
       "      <td>1.602758e+18</td>\n",
       "      <td>1.547</td>\n",
       "      <td>0.305</td>\n",
       "      <td>1.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.471105e+17</td>\n",
       "      <td>8.875457e+12</td>\n",
       "      <td>1.193</td>\n",
       "      <td>1.043</td>\n",
       "      <td>2.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.530300e+04</td>\n",
       "      <td>1.602736e+18</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.050174e+09</td>\n",
       "      <td>1.602750e+18</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.415568e+17</td>\n",
       "      <td>1.602760e+18</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.306720e+18</td>\n",
       "      <td>1.602764e+18</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.602762e+18</td>\n",
       "      <td>1.602774e+18</td>\n",
       "      <td>18.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>38.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author_id            id  nb_hashtags  nb_exclamation    nb_maj\n",
       "count  9.054000e+03  9.054000e+03     9054.000        9054.000  9054.000\n",
       "mean   6.905736e+17  1.602758e+18        1.547           0.305     1.997\n",
       "std    6.471105e+17  8.875457e+12        1.193           1.043     2.296\n",
       "min    6.530300e+04  1.602736e+18        1.000           0.000     0.000\n",
       "25%    1.050174e+09  1.602750e+18        1.000           0.000     1.000\n",
       "50%    8.415568e+17  1.602760e+18        1.000           0.000     1.000\n",
       "75%    1.306720e+18  1.602764e+18        2.000           0.000     2.000\n",
       "max    1.602762e+18  1.602774e+18       18.000          22.000    38.000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.describe(), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5a92eb-2897-4ee9-b511-d8fe0661b378",
   "metadata": {},
   "source": [
    "Il faut ajouter une variable \"cluster\" dans le dataframe, qui contient l'identifiant du cluster auquel appartient chaque utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a986c4-a6fd-43a6-9966-0199769af45c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
